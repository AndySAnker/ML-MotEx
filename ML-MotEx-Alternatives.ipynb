{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> Welcome to alternatives to ML-MotEx </center></h1>\n",
    "\n",
    "# First import modules, set seed parameters and import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import time, shap, random\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from bayes_opt import BayesianOptimization\n",
    "import pandas as pd\n",
    "from ase.io import read\n",
    "from diffpy.Structure import Structure, Atom\n",
    "from diffpy.srfit.pdf import PDFContribution, PDFParser, PDFGenerator\n",
    "from diffpy.srfit.fitbase import FitRecipe, FitResults, Profile, FitContribution\n",
    "from diffpy.srreal.pdfcalculator import DebyePDFCalculator\n",
    "from scipy.optimize.minpack import leastsq\n",
    "\n",
    "np.random.seed(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Import_Dataset(FileName):\n",
    "    \"\"\"This function loads a catalogue of structures with their corresponding Rwp values and split the dataset \n",
    "    into a training set and validation set with features and labels.\"\"\"\n",
    "    # load data\n",
    "    dataset = np.loadtxt(FileName, delimiter=\" \", skiprows=0)\n",
    "    dataset_original = dataset.copy()\n",
    "\n",
    "    # Split into training and validation set\n",
    "    dataset_train = dataset[:int(len(dataset)*0.8)]\n",
    "    dataset_val = dataset[int(len(dataset)*0.8):len(dataset)]\n",
    "    \n",
    "    # split data into features (X) and labels (y)\n",
    "    X_train = dataset_train[:,2:len(dataset)+1]\n",
    "    y_train = dataset_train[:,1]\n",
    "    X_val = dataset_val[:,2:len(dataset)+1]\n",
    "    y_val = dataset_val[:,1]\n",
    "    \n",
    "    print(\"Number of Training Data:\", len(y_train))\n",
    "    print(\"Number of Validation Data:\", len(y_val))\n",
    "        \n",
    "    return X_train, y_train, X_val, y_val\n",
    "    \n",
    "def fitting(structure_catalogue, plot, index):\n",
    "    \"\"\"This function takes in a 'starting_model', and an 'index' from the 'structure_catalogue'. It generates the \n",
    "    corresponding structure and fit it to the 'Experimental_Data'.\"\"\"\n",
    "    \n",
    "    # Read structure and divide it into two lists: Atoms we want to iterate (W) and atoms we do not iterate (O)\n",
    "    stru = read(starting_model)\n",
    "    xyz = stru.get_positions()\n",
    "    xyz_W = xyz[:NumW].copy()\n",
    "    xyz_O = xyz[NumW:len(xyz)].copy()\n",
    "    keep_O = np.zeros(len(xyz_O))\n",
    "    h = 0\n",
    "    # Cycle through W atoms and delete W according to index 0's from permutation\n",
    "    permutations = np.asarray(structure_catalogue)[:,1:]\n",
    "    for j in range(len(xyz_W)):\n",
    "        if permutations[index][j] == 0:\n",
    "            xyz_W = np.delete(xyz_W,j - h,0)\n",
    "            h = h+1   \n",
    "    # Cycle through all atoms that is not iteratable and test if it is within the threshold distance. Delete atoms with no bonds\n",
    "    for j in range(len(xyz_O)):        \n",
    "        for k in range(len(xyz_W)):\n",
    "            dist = np.linalg.norm(xyz_W[k] - xyz_O[j])\n",
    "            if dist < threshold:    \n",
    "                keep_O[j] = 1\n",
    "                break\n",
    "    h = 0            \n",
    "    for j in range(len(xyz_O)):\n",
    "        if keep_O[j] == 0:\n",
    "            xyz_O = np.delete(xyz_O,j - h, 0)\n",
    "            h += 1\n",
    "            \n",
    "    # Create structure for iterable (W) and non-iterable (O) atoms and combine them\n",
    "    W_cluster = Structure([Atom('W', xi) for xi in xyz_W])\n",
    "    O_cluster = Structure([Atom('O', xi) for xi in xyz_O])\n",
    "    cluster = W_cluster + O_cluster\n",
    "    \n",
    "    # Make a standard cluster refinement using Diffpy-CMI\n",
    "    # Import the data and make it a PDFprofile. Define the range of the data that will be used in the fit.\n",
    "    pdfprofile = Profile()\n",
    "    pdfparser = PDFParser()\n",
    "    pdfparser.parseFile(Experimental_Data)\n",
    "    pdfprofile.loadParsedData(pdfparser)\n",
    "    pdfprofile.setCalculationRange(xmin = 1.6, xmax = 10)\n",
    "\n",
    "    # Setup the PDFgenerator that calculates the PDF from the structure\n",
    "    pdfgenerator_cluster = PDFGenerator(\"G\")\n",
    "    # Add the profile and both generators to the PDFcontribution\n",
    "    pdfcontribution = FitContribution(\"pdf\")\n",
    "    pdfcontribution.setProfile(pdfprofile, xname=\"r\") \n",
    "    pdfcontribution.addProfileGenerator(pdfgenerator_cluster)\n",
    "    \n",
    "    pdfgenerator_cluster.setQmin(0.7)\n",
    "    pdfgenerator_cluster.setQmax(20)\n",
    "    pdfgenerator_cluster._calc.evaluatortype = 'OPTIMIZED'\n",
    "    pdfgenerator_cluster.setStructure(cluster, periodic = False)\n",
    "\n",
    "    # Use scaling factors proportional to molar content\n",
    "    pdfcontribution.setEquation('mc*G')\n",
    "\n",
    "    # Define the recipe to do the fit and add it to the PDFcontribution\n",
    "    recipe = FitRecipe()\n",
    "    recipe.addContribution(pdfcontribution)\n",
    "\n",
    "    # Avoid too much output during fitting \n",
    "    recipe.clearFitHooks()\n",
    "\n",
    "    # Add the scale factor.\n",
    "    recipe.addVar(pdfcontribution.mc, 1.0, tag = \"scale\")\n",
    "    \n",
    "    # Add the instrumental parameters to the two generators\n",
    "    pdfgenerator_cluster.qdamp.value = 0.05\n",
    "    pdfgenerator_cluster.qbroad.value = 0.01\n",
    "\n",
    "    # Add the delta2 parameters, and make sure it cannot take unphysical values\n",
    "    recipe.addVar(pdfgenerator_cluster.delta2, 0, name = \"delta2_cluster\", tag = \"delta2\")\n",
    "\n",
    "    # Add ADP and \"cell\" for the cluster\n",
    "    phase_cluster = pdfgenerator_cluster.phase\n",
    "    atoms = phase_cluster.getScatterers()\n",
    "    lat = phase_cluster.getLattice()\n",
    "\n",
    "    recipe.newVar(\"zoomscale1\", 1.0, tag = \"lat\")\n",
    "    recipe.newVar(\"zoomscale2\", 1.0, tag = \"lat\")\n",
    "    recipe.newVar(\"zoomscale3\", 1.0, tag = \"lat\")\n",
    "    recipe.constrain(lat.a, 'zoomscale1')\n",
    "    recipe.constrain(lat.b, 'zoomscale2')\n",
    "    recipe.constrain(lat.c, 'zoomscale3')\n",
    "\n",
    "    W_cluster = recipe.newVar(\"W_Biso_cluster1\", 0.4, tag = 'adp_w')\n",
    "    O_cluster = recipe.newVar(\"O_Biso_cluster1\", 0.4, tag = 'adp_o')\n",
    "\n",
    "    for atom in atoms:\n",
    "        if atom.element.title() == \"W\":\n",
    "            recipe.constrain(atom.Biso, W_cluster)\n",
    "        elif atom.element.title() == \"O\":\n",
    "            recipe.constrain(atom.Biso, O_cluster)\n",
    "\n",
    "    recipe.restrain(\"zoomscale1\", lb = 0.99, ub = 1.01, sig = 0.001)\n",
    "    recipe.restrain(\"zoomscale2\", lb = 0.99, ub = 1.01, sig = 0.001)\n",
    "    recipe.restrain(\"zoomscale3\", lb = 0.99, ub = 1.01, sig = 0.001)\n",
    "    \n",
    "    #free parameters are set\n",
    "    recipe.fix('all')\n",
    "    recipe.free(\"scale\", \"lat\")\n",
    "\n",
    "    # Turn off printout of iteration number.\n",
    "    #recipe.clearFitHooks()\n",
    "\n",
    "    # We can now execute the fit using scipy's least square optimizer.\n",
    "    leastsq(recipe.residual, recipe.getValues())\n",
    "    \n",
    "    # We calculate the goodness-of-fit, Rwp\n",
    "    g = recipe.pdf.profile.y\n",
    "    gcalc = recipe.pdf.evaluate()\n",
    "    rfactor1 = np.sqrt(sum((g - gcalc)**2) / sum((g)**2))\n",
    "    \n",
    "    # if plot == 1 it will also plot the fit\n",
    "    if plot == 1:\n",
    "        print (\"FIT RESULTS\\n\")\n",
    "        res1 = FitResults(recipe)\n",
    "        print (res1)\n",
    "\n",
    "        # Plot the observed and refined PDF.\n",
    "        # Get the experimental data from the recipe\n",
    "        r = recipe.pdf.profile.x\n",
    "        gobs = recipe.pdf.profile.y\n",
    "\n",
    "        # Get the calculated PDF and compute the difference between the calculated and measured PDF\n",
    "        gcalc = recipe.pdf.evaluate()\n",
    "        baseline = 1.1 * gobs.min()\n",
    "        gdiff = gobs - gcalc\n",
    "\n",
    "        # Plot!\n",
    "        plt.figure()\n",
    "        plt.plot(r, gobs, 'bo', label=\"G(r) data\")\n",
    "        plt.plot(r, gcalc, 'r-', label=\"G(r) fit\")\n",
    "        plt.plot(r, gdiff + baseline, 'g-', label=\"G(r) diff\")\n",
    "        plt.plot(r, np.zeros_like(r) + baseline, 'k:')\n",
    "        plt.xlabel(r\"$r (\\AA)$\")\n",
    "        plt.ylabel(r\"$G (\\AA^{-2})$\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.show()\n",
    "    return rfactor1\n",
    "\n",
    "def fitting_multiprocess(structure_catalogue, SaveName, cores=1):\n",
    "    \"\"\"This function runs the refinement of all the structures in the structure catalogue using multiprocessing\"\"\"\n",
    "    start_time = time.time()\n",
    "    values = []\n",
    "    # Set up multiprocessing refinement\n",
    "    fitindex = range(len(structure_catalogue))\n",
    "    p = Pool(processes=cores)\n",
    "    plot = 0\n",
    "    func = partial(fitting, structure_catalogue, plot)\n",
    "    results = p.map(func, fitindex)\n",
    "    p.close()\n",
    "    p.join()\n",
    "    \n",
    "    # Start refinement and append results to lists\n",
    "    for i in fitindex:\n",
    "        if i % 100 == 0:\n",
    "            print (\"I have now fitted: \", str(i) + \" structures out of \" + str(len(structure_catalogue)))\n",
    "        rw = results[i]\n",
    "        values.append(i)\n",
    "        values.append(rw)\n",
    "    values = np.reshape(values,(int(len(values)/2) , 2))\n",
    "    \n",
    "    # Save results in format that is suitable for Machine Learning\n",
    "    print (\"Best fit\")\n",
    "    print (values[np.argmin(values[:,1])])\n",
    "    print(\"Total execution time: %.3fs\" % (time.time()-start_time))\n",
    "    Result = np.column_stack([values, np.asarray(structure_catalogue)[values[:,0].astype(int)]])\n",
    "    np.savetxt(SaveName, Result)\n",
    "    return Result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First we try to weight the atom contributions without use of ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data: 8000\n",
      "Number of Validation Data: 2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.34211816, 0.35514468, 0.34529134, 0.35309727, 0.33877448,\n",
       "       0.35206208, 0.34034462, 0.35062888, 0.34047383, 0.34878394,\n",
       "       0.34502808, 0.34782042, 0.33975733, 0.35009632, 0.3418833 ,\n",
       "       0.35845513, 0.34278846, 0.34962394, 0.342858  , 0.34319284,\n",
       "       0.34110077, 0.34727624, 0.33939427, 0.35016531])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saveFits = \"Training_Data/structure_109725.txt\" # Name of the saved fits file\n",
    "\n",
    "# Import dataset\n",
    "X_train, y_train, X_val, y_val = Import_Dataset(saveFits)\n",
    "\n",
    "for structure_number in range(len(y_train)):\n",
    "    where_one = np.where(X_train[structure_number,:] == 1)\n",
    "    X_train[structure_number,where_one] = y_train[structure_number]\n",
    "X_train = X_train.mean(0)\n",
    "\n",
    "X_train[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atom contribution are calculated to: \n",
      "Atom # 1:  0.3421181568279513  Colorcode:  #ddc858\n",
      "Atom # 2:  0.3551446799287627  Colorcode:  #2e416d\n",
      "Atom # 3:  0.3452913361911336  Colorcode:  #afa471\n",
      "Atom # 4:  0.3530972691010328  Colorcode:  #4c556c\n",
      "Atom # 5:  0.3387744833823796  Colorcode:  #fee838\n",
      "Atom # 6:  0.3520620826769287  Colorcode:  #595e6e\n",
      "Atom # 7:  0.3403446204115771  Colorcode:  #f8df3c\n",
      "Atom # 8:  0.350628875409687  Colorcode:  #6b6d72\n",
      "Atom # 9:  0.34047382771166057  Colorcode:  #f7de3e\n",
      "Atom # 10:  0.34878393871216035  Colorcode:  #807f78\n",
      "Atom # 11:  0.3450280834129964  Colorcode:  #b3a670\n",
      "Atom # 12:  0.34782042132729524  Colorcode:  #8d8878\n",
      "Atom # 13:  0.3397573275252268  Colorcode:  #fee838\n",
      "Atom # 14:  0.3500963218754674  Colorcode:  #717274\n",
      "Atom # 15:  0.341883304770805  Colorcode:  #e0cb56\n",
      "Atom # 16:  0.35845512549338987  Colorcode:  #00224e\n",
      "Atom # 17:  0.3427884640247057  Colorcode:  #d3c05f\n",
      "Atom # 18:  0.3496239413092981  Colorcode:  #767676\n",
      "Atom # 19:  0.34285799592703825  Colorcode:  #d2c060\n",
      "Atom # 20:  0.3431928391255018  Colorcode:  #cdbb63\n",
      "Atom # 21:  0.3411007704164948  Colorcode:  #edd54a\n",
      "Atom # 22:  0.34727624303977406  Colorcode:  #948e77\n",
      "Atom # 23:  0.33939427412803647  Colorcode:  #fee838\n",
      "Atom # 24:  0.3501653094531368  Colorcode:  #707173\n"
     ]
    }
   ],
   "source": [
    "AtomContributionValues = X_train\n",
    "\n",
    "Norm_AtomContributionValues = AtomContributionValues.copy()\n",
    "# Normalise the AtomContributionValues and get the RGB color in viridis.reverse\n",
    "amin, amax = min(Norm_AtomContributionValues), max(Norm_AtomContributionValues)\n",
    "for i, val in enumerate(Norm_AtomContributionValues):\n",
    "    Norm_AtomContributionValues[i] = (val-amin) / (amax-amin)\n",
    "Norm_AtomContributionValues_ph = Norm_AtomContributionValues.copy()\n",
    "Norm_AtomContributionValues_ph.sort()\n",
    "\n",
    "# Normalise such that a threshold is set on the the 10 % lowest and 10 % highest atoms\n",
    "norm = mpl.colors.Normalize(vmin=Norm_AtomContributionValues_ph[round((len(Norm_AtomContributionValues))/10)], vmax=Norm_AtomContributionValues_ph[-round((len(Norm_AtomContributionValues))/10)])\n",
    "cmap = mpl.cm.cividis_r\n",
    "\n",
    "print (\"Atom contribution are calculated to: \")\n",
    "for i in range(1,len(AtomContributionValues)):\n",
    "    m = mpl.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "    print (\"Atom #\", str(i) + \": \", str(AtomContributionValues[i]), \" Colorcode: \", mpl.colors.rgb2hex(m.to_rgba(Norm_AtomContributionValues[i])))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we try simply to remove each atom’s partial and comparing the Rw?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutations Succeeded\n",
      "We show the first 10 structures in the catalogue:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[23.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " [23.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " [23.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " [23.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " [23.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " [23.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " [23.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " [23.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " [23.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " [23.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " [23.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " [23.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " [23.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " [23.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " [23.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " [23.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " [23.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " [23.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " [23.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " [23.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " [23.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " [23.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " [23.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0],\n",
       " [23.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starting_model = \"Structure_Models/109725.xyz\" # Name of the starting model file\n",
    "Number_of_structures = 10000 # Number of structures made to the structure catalogue\n",
    "NumW = 24 # Number of atoms that should be permuted in the starting model\n",
    "threshold = 2.5 # Thredshold for W - O bond\n",
    "\n",
    "def structure_catalogue_maker(Number_of_atoms):\n",
    "    structure_catalogue = []\n",
    "    for i in range(Number_of_atoms):\n",
    "        my_list = np.ones((25,))\n",
    "        my_list[0] = 23\n",
    "        my_list[i+1] = 0\n",
    "        my_list = list(my_list)\n",
    "        structure_catalogue.append(my_list)\n",
    "    print (\"Permutations Succeeded\")\n",
    "    return structure_catalogue\n",
    "\n",
    "\n",
    "\n",
    "structure_catalogue = structure_catalogue_maker(Number_of_atoms=NumW)\n",
    "print (\"We show the first 10 structures in the catalogue:\")\n",
    "structure_catalogue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experimental_Data = \"Experimental_Data/DanMAX_AlphaKeggin.gr\" # Name of the experimental file\n",
    "saveFits = \"Training_Data/structure_109725_Alternative.txt\" # Name of the saved fits file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have now fitted:  0 structures out of 24\n",
      "Best fit\n",
      "[1.         0.57189986]\n",
      "Total execution time: 4.194s\n",
      "The best fitting structure is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.61399193, 23.        ,  0.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 1.        ,  0.57189986, 23.        ,  1.        ,  0.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 2.        ,  0.6180346 , 23.        ,  1.        ,  1.        ,\n",
       "         0.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 3.        ,  0.57443284, 23.        ,  1.        ,  1.        ,\n",
       "         1.        ,  0.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 4.        ,  0.61036954, 23.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 5.        ,  0.58128758, 23.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  0.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 6.        ,  0.61399193, 23.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  0.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 7.        ,  0.57189986, 23.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         0.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 8.        ,  0.6180346 , 23.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  0.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 9.        ,  0.57443284, 23.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [10.        ,  0.61036954, 23.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  0.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [11.        ,  0.58128758, 23.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  0.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [12.        ,  0.61399193, 23.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         0.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [13.        ,  0.57189986, 23.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  0.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [14.        ,  0.6180346 , 23.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [15.        ,  0.57443284, 23.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  0.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [16.        ,  0.61036954, 23.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  0.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [17.        ,  0.58128758, 23.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         0.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [18.        ,  0.61399193, 23.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  0.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [19.        ,  0.57189986, 23.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  0.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [20.        ,  0.6180346 , 23.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  0.        ,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [21.        ,  0.57443284, 23.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  0.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [22.        ,  0.61036954, 23.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [23.        ,  0.58128758, 23.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result = fitting_multiprocess(structure_catalogue, SaveName=saveFits, cores=None)\n",
    "print (\"The best fitting structure is:\")\n",
    "Result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "AtomContributionValues = []\n",
    "for i in range(len(Result)):\n",
    "    AtomContributionValues.append(1-Result[i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atom contribution are calculated to: \n",
      "Atom # 1:  0.3860080717514075  Colorcode:  #e8d24f\n",
      "Atom # 2:  0.4281001421674805  Colorcode:  #00224e\n",
      "Atom # 3:  0.38196540095101417  Colorcode:  #fee838\n",
      "Atom # 4:  0.42556716179839205  Colorcode:  #002c66\n",
      "Atom # 5:  0.38963045928590356  Colorcode:  #d2c060\n",
      "Atom # 6:  0.4187124169054345  Colorcode:  #36466c\n",
      "Atom # 7:  0.38600807170540996  Colorcode:  #e8d24f\n",
      "Atom # 8:  0.4281001420552061  Colorcode:  #00224e\n",
      "Atom # 9:  0.3819654009830128  Colorcode:  #fee838\n",
      "Atom # 10:  0.4255671618861764  Colorcode:  #002c66\n",
      "Atom # 11:  0.38963045921410233  Colorcode:  #d2c060\n",
      "Atom # 12:  0.41871241694226435  Colorcode:  #36466c\n",
      "Atom # 13:  0.38600807158521844  Colorcode:  #e8d24f\n",
      "Atom # 14:  0.4281001421205406  Colorcode:  #00224e\n",
      "Atom # 15:  0.3819654009906399  Colorcode:  #fee838\n",
      "Atom # 16:  0.4255671617868457  Colorcode:  #002c66\n",
      "Atom # 17:  0.38963045924543427  Colorcode:  #d2c060\n",
      "Atom # 18:  0.4187124169770613  Colorcode:  #36466c\n",
      "Atom # 19:  0.38600807182067876  Colorcode:  #e8d24f\n",
      "Atom # 20:  0.42810014199699187  Colorcode:  #00224e\n",
      "Atom # 21:  0.38196540102771537  Colorcode:  #fee838\n",
      "Atom # 22:  0.4255671618498308  Colorcode:  #002c66\n",
      "Atom # 23:  0.3896304593276584  Colorcode:  #d2c060\n",
      "Atom # 24:  0.41871241696628037  Colorcode:  #36466c\n"
     ]
    }
   ],
   "source": [
    "Norm_AtomContributionValues = AtomContributionValues.copy()\n",
    "# Normalise the AtomContributionValues and get the RGB color in viridis.reverse\n",
    "amin, amax = min(Norm_AtomContributionValues), max(Norm_AtomContributionValues)\n",
    "for i, val in enumerate(Norm_AtomContributionValues):\n",
    "    Norm_AtomContributionValues[i] = (val-amin) / (amax-amin)\n",
    "Norm_AtomContributionValues_ph = Norm_AtomContributionValues.copy()\n",
    "Norm_AtomContributionValues_ph.sort()\n",
    "\n",
    "# Normalise such that a threshold is set on the the 10 % lowest and 10 % highest atoms\n",
    "norm = mpl.colors.Normalize(vmin=Norm_AtomContributionValues_ph[round((len(Norm_AtomContributionValues))/10)], vmax=Norm_AtomContributionValues_ph[-round((len(Norm_AtomContributionValues))/10)])\n",
    "cmap = mpl.cm.cividis_r\n",
    "\n",
    "print (\"Atom contribution are calculated to: \")\n",
    "for i in range(len(AtomContributionValues)):\n",
    "    m = mpl.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "    print (\"Atom #\", str(i+1) + \": \", str(AtomContributionValues[i]), \" Colorcode: \", mpl.colors.rgb2hex(m.to_rgba(Norm_AtomContributionValues[i])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
